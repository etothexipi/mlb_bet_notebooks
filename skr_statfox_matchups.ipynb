{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape StatFox for Current and Historical Matchup Stats\n",
    "`Notebooks/skr_statfox.ipynb`\n",
    "###### `BY: Jonathan Sims` \n",
    "###### `MODIFIED: 2019-06-15` (created)\n",
    "- GOAL: Scrape daily to build up historical matchup tables\n",
    "- USE: Treat each matchup page as one obs in RF model to asses feature importance\n",
    "    - Useful before spending time building up game/pitch/player-level count data \n",
    "    - Compare odds here with odds from VegasInsider to look for odds movement features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9fa922f2445b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchrome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from selenium import webdriver\t\n",
    "from sqlalchemy import create_engine\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MySQL Connector needs Python float, not numpy float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def float64_to_float(x):\n",
    "    try:\n",
    "        if x.dtype == 'float64':\n",
    "            return float(x)\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert American betting lines to probability value satisfying E[x]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def american_to_probability(x):\n",
    "    \"\"\"\n",
    "    Turns American +/- odds into probability 0 to 1 inclusive\n",
    "    \"\"\"\n",
    "    if x.find('-') > -1 and x.find('+') > -1:\n",
    "        print('Error: + and - signs found in betting line string') \n",
    "\n",
    "    elif x.find('-') > -1:\n",
    "        num = int(x.replace(' ','').replace('-',''))\n",
    "        if num < 100:\n",
    "            print('Error: Betting line outside bounds [100,+inf]')\n",
    "        else:\n",
    "            pr = num/(100+num)\n",
    "            return pr\n",
    "\n",
    "    elif x.find('+') > -1:\n",
    "        num = int(x.replace(' ','').replace('+',''))\n",
    "        if num < 100 or num > 999:\n",
    "            print('Error: Betting line outside bounds [100,999]')\n",
    "        else:\n",
    "            pr = 100/(100+num)\n",
    "            return pr\n",
    "\n",
    "    else:\n",
    "        print('Error: No sign found in betting line string')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame([['-120','-120+'],['+214','214'],['-123','-1123'],['-120','+90']])\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for y in df.columns:\n",
    "    df[y] = df[y].apply(lambda x : american_to_probability(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set chrome options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all column names from `skr_statfox_matchups_cols.py` run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# all_cols = pd.read_pickle('pickles/statfox_matchups_cols.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get list of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "glhead = pd.read_csv('GLHEADER.CSV',header=None)\n",
    "gms = pd.read_csv('GL2018.CSV',header=0,names=list(glhead[0]))\n",
    "gms = gms[['date','team_h','team_v','score_h','score_v']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### translate 3 letter team name to full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "teams = pd.read_csv('TEAM_NAMES.CSV',header=0,index_col=['name1'],usecols=['name1','name3'])\n",
    "teams = teams['name3'].to_dict()\n",
    "\n",
    "gms['team_h'] = gms['team_h'].map(lambda x: teams[x.upper()])\n",
    "gms['team_v'] = gms['team_v'].map(lambda x: teams[x.upper()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert db connection string. Eff security or other good practices for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mysql",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3c5a20075e6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mysql+mysqlconnector://jsimssy:1u2kIr&vDr8!lal@ml-pipeline-01.cf1vgzngw30x.us-east-2.rds.amazonaws.com:3306/mlb_bet_dev?use_pure=True'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'strategy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mdbapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dbapi'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sqlalchemy\\dialects\\mysql\\mysqlconnector.py\u001b[0m in \u001b[0;36mdbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mmysql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named mysql"
     ]
    }
   ],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://jsimssy:1u2kIr&vDr8!lal@ml-pipeline-01.cf1vgzngw30x.us-east-2.rds.amazonaws.com:3306/mlb_bet_dev?use_pure=True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main scrape code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dt = ''\n",
    "tm_h = ''\n",
    "tm_v = ''\n",
    "sc_h = 0\n",
    "sc_v = 0\n",
    "\n",
    "# for x in range(len(gms)):\n",
    "# for x in range(43,47):\n",
    "for x in range(52,55):\n",
    "    \n",
    "    try:\n",
    "        dt = str(gms.loc[x,'date'])\n",
    "        tm_h = str(gms.loc[x,'team_h']).replace(' ','')                                                              \n",
    "        tm_v = str(gms.loc[x,'team_v']).replace(' ','')\n",
    "        sc_h = gms.loc[x,'score_h']\n",
    "        sc_v = gms.loc[x,'score_v']\n",
    "        \n",
    "        # Adjust URL if second game of double header\n",
    "        if (x > 1) and (str(gms.loc[x-1,'date']) == dt) and (str(gms.loc[x-1,'team_h']).replace(' ','') == tm_h):\n",
    "            tm_h = tm_h+'2'\n",
    "            \n",
    "        url = 'http://foxsheets.statfoxsports.com/foxsheets.aspx?s=mlb&g='+dt+tm_h+'&r=at'\n",
    "        driver = webdriver.Chrome(options=options,executable_path='/home/ec2-user/./chromedriver')\t\n",
    "        driver.get(url)\t\n",
    "        ls = pd.DataFrame([])\n",
    "        ls_a = pd.DataFrame([])\n",
    "        \n",
    "        # Primary table in schema. Game, team, result, odds. Indexed on YYYYMMDDBBB where B is board number\n",
    "        sub_root = '//*[@id=\"dnn_ctr490_View_UP\"]/table[3]/tbody/tr[9]/td/table/tbody/tr/td/table/tbody/tr/td[2]/table/tbody/tr/td/table/tbody/tr/td'\n",
    "        stats = driver.find_element_by_xpath(sub_root)\n",
    "        content_html = stats.get_attribute(\"innerHTML\")\t\n",
    "#         brd_v = pd.read_html(content_html)[0][0].loc[2]\n",
    "#         brd_h = pd.read_html(content_html)[0][0].loc[3]\n",
    "        games = pd.DataFrame([[1,int(dt)],[1,int(dt)]], columns=['game_id','date'])\n",
    "        games[['board','team_name','line_open','line_close']] = pd.read_html(content_html)[0].iloc[2:4][[0,1,2,4]].reset_index(drop=True)\n",
    "        for c in ['line_open','line_close']:\n",
    "            games[c] = games[c].apply(lambda x : american_to_probability(x))\n",
    "        games['game_id'] = (games['date'])*1000 + pd.to_numeric(games['board'])\n",
    "        games = games.drop(columns=['board'])\n",
    "        games['date'] = pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")\n",
    "        games['home'] = [False,True]\n",
    "        games.to_sql(name='games', con=engine, if_exists='append', index=False)        \n",
    "        \n",
    "        # Dont increase tr for regular (non double header) games\n",
    "        plus1 = 0\n",
    "        \n",
    "    # Account for double headers\n",
    "    except:\n",
    "        try:            \n",
    "            # Get Game Board values for each team to use as index with date\n",
    "            sub_root = '//*[@id=\"dnn_ctr490_View_UP\"]/table[3]/tbody/tr[10]/td/table/tbody/tr/td/table/tbody/tr/td[2]/table/tbody/tr/td/table/tbody/tr/td'\n",
    "            stats = driver.find_element_by_xpath(sub_root)\n",
    "            content_html = stats.get_attribute(\"innerHTML\")\t\n",
    "            brd_v = pd.read_html(content_html)[0][0].loc[2]\n",
    "            brd_h = pd.read_html(content_html)[0][0].loc[3]\n",
    "            \n",
    "            # Increase tr in main block below by 1\n",
    "            plus1 = 1\n",
    "            \n",
    "        except:\n",
    "            print('Error: Did not retreive game and board info for match')\n",
    "            print('...url was: ',url)\n",
    "            print('...loop iteration was: ',x)\n",
    "            continue\n",
    "    \n",
    "#     for tr in [14,15,16,18,19,20,23,25]:\n",
    "    for tr in [14]:\n",
    "        \n",
    "#         try:       \n",
    "            # Adjust tr if double header (tr + plus1)\n",
    "            sub_root = '//*[@id=\"dnn_ctr490_View_UP\"]/table[3]/tbody/tr['+str(tr+plus1)+']/td/table'\n",
    "            stats = driver.find_element_by_xpath(sub_root)\n",
    "            content_html = stats.get_attribute(\"innerHTML\")\t\n",
    "            \n",
    "            if tr in [14,18]:\n",
    "                if tr == 14:\n",
    "                    section = 'overall_v'\n",
    "                    board = brd_v\n",
    "                elif tr == 18:\n",
    "                    section = 'overall_h'\n",
    "                    board = brd_h\n",
    "                ls = pd.read_html(content_html,index_col=[0],header=[2])[0]             \n",
    "                # Parse columns with multiple values e.g. Win and Loss or Over and Under\n",
    "                ls[['W','L']] = ls['W-L'].str.split(\"-\",expand=True)\n",
    "                ls[['O','U']] = ls['O-U'].str.split(\"-\",expand=True)\n",
    "                ls = ls.drop(columns=['W-L','O-U'])                \n",
    "                # Make sql table for each row index (All games, night games, etc.)\n",
    "                for i in ls.index:\n",
    "                    Y = pd.DataFrame(ls.loc[i].apply(lambda x : float64_to_float(x))).transpose()\n",
    "                    Y['game_id'] = dt+'_'+board\n",
    "                    Y = Y.set_index(['game_id'],drop=True)\n",
    "                    table = section+'_'+i\n",
    "                    Y.to_sql(name=table, con=engine, if_exists='append', index=False)\n",
    "                \n",
    "            elif tr in [15,19]:\n",
    "                if tr == 15:\n",
    "                    section = 'hitNfield_v'\n",
    "                    board = brd_v\n",
    "                elif tr == 19:\n",
    "                    section = 'hitNfield_h'\n",
    "                    board = brd_h\n",
    "                ls = pd.read_html(content_html,index_col=[0],header=[2])[0]                                \n",
    "                # Make sql table for each row index (All games, night games, etc.)\n",
    "                for i in ls.index:\n",
    "                    Y = pd.DataFrame(ls.loc[i].apply(lambda x : float64_to_float(x))).transpose()\n",
    "                    Y['idx'] = dt+'_'+board\n",
    "                    table = section+'_'+i\n",
    "                    Y.to_sql(name=table, con=engine, if_exists='append', index=False)\n",
    "                \n",
    "            elif tr in [16,20]:\n",
    "                if tr == 16:\n",
    "                    section = 'bullpen_v'\n",
    "                    board = brd_v\n",
    "                elif tr == 20:\n",
    "                    section = 'bullpen_h'\n",
    "                    board = brd_h\n",
    "                ls = pd.read_html(content_html,index_col=[0],header=[1])[0]                                \n",
    "                ls[['W','L']] = ls['W-L'].str.split(\"-\",expand=True)\n",
    "                ls = ls.drop(columns=['W-L'])                \n",
    "                # Make sql table for each row index (All games, night games, etc.)\n",
    "                for i in ls.index:\n",
    "                    Y = pd.DataFrame(ls.loc[i].apply(lambda x : float64_to_float(x))).transpose()\n",
    "                    Y['idx'] = dt+'_'+board\n",
    "                    table = section+'_'+i\n",
    "                    Y.to_sql(name=table, con=engine, if_exists='append', index=False)\n",
    "                \n",
    "            elif tr in [23,25]:\n",
    "                if tr == 23:\n",
    "                    section = 'matchups_v'\n",
    "                    board = brd_v\n",
    "                elif tr == 25:\n",
    "                    section = 'matchups_h'\n",
    "                    board = brd_h\n",
    "                ls = pd.read_html(content_html,header=[2])[0]    \n",
    "                # Make pitching matchup date relative to game day, not raw dates\n",
    "                ls['Date'] = pd.to_datetime(ls['Date']) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")\n",
    "                ls = ls.set_index('Date')\n",
    "                # Split Score and Tot, Ovr/Und to multiple variables\n",
    "                ls[['score_for','score_against']] = ls['Score'].str.split(\"-\",expand=True)\n",
    "                ls[['ovrund_num','ovrund']] = ls['Tot.'].str.split(\" \",expand=True)\n",
    "                ls = ls.drop(columns=['Score','Tot.'])      \n",
    "                \n",
    "                # Make sql table for each row index (All games, night games, etc.)\n",
    "                for i in ls.index:\n",
    "                    # Only want negative (past) matchup results, future games are null\n",
    "                    if i.days < 0:\n",
    "                        Y = pd.DataFrame(ls.loc[i].apply(lambda x : float64_to_float(x))).transpose()\n",
    "                        Y['idx'] = int(dt)*1000 + int(board)\n",
    "                        table = section+'_'+str(i.days)\n",
    "                        Y.to_sql(name=table, con=engine, if_exists='append', index=False)\n",
    "                \n",
    "#             ls = pd.concat([ls], keys=[table])\n",
    "#             ls = ls.stack()\n",
    "#             ls_a = pd.concat([ls_a,ls])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "        except:\n",
    "            # Check for normal pagenotfound verses error parsing\n",
    "            try:\n",
    "                xpath_notfound = '//*[@src=\"/images/foxsheetnotfound.gif\"]'\n",
    "                driver.find_element_by_xpath(xpath_notfound)\n",
    "                print('No game exists for ',tm_h,' on ',dt)\n",
    "                print('Error: loop iteration = ',x)\n",
    "                continue\n",
    "                \n",
    "            except:\n",
    "                err_msg = 'Possible change to HTML tables structure \\n'\n",
    "                err_msg += err_msg + 'Check the URL: ' + url\n",
    "                print('Error: loop iteration = ',x)\n",
    "                continue\n",
    "\n",
    "    # Close all Chrome sessions to save memory between loops\n",
    "    driver.quit()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "games[['line_open','line_close']].apply(american_to_probability, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "                for i in ls.index:\n",
    "                    Y = pd.DataFrame(ls.loc[i].apply(lambda x : float64_to_float(x))).transpose()\n",
    "                    Y['game_id'] = dt+'_'+board\n",
    "                    Y = Y.set_index(['game_id'],drop=True)\n",
    "                    table = section+'_'+i\n",
    "                    Y.to_sql(name=table, con=engine, if_exists='append', index=True, index_labels=['game_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Y.to_sql?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "board = brd_v \n",
    "Y = pd.DataFrame([int(dt)*1000 + int(board)], columns=['idx'])\n",
    "Y = Y.concat(ls.loc[i].apply(lambda x : float64_to_float(x)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = 45\n",
    "\n",
    "dt = str(gms.loc[x,'date'])\n",
    "tm_h = str(gms.loc[x,'team_h']).replace(' ','')                                                              \n",
    "tm_v = str(gms.loc[x,'team_v']).replace(' ','')\n",
    "sc_h = gms.loc[x,'score_h']\n",
    "sc_v = gms.loc[x,'score_v']\n",
    "\n",
    "# Adjust URL if second game of double header\n",
    "if (x > 1) and (str(gms.loc[x-1,'date']) == dt) and (str(gms.loc[x-1,'team_h']).replace(' ','') == tm_h):\n",
    "    tm_h = tm_h+'2'\n",
    "\n",
    "url = 'http://foxsheets.statfoxsports.com/foxsheets.aspx?s=mlb&g='+dt+tm_h+'&r=at'\n",
    "driver = webdriver.Chrome(options=options,executable_path='/home/ec2-user/./chromedriver')\t\n",
    "driver.get(url)\t\n",
    "ls = pd.DataFrame([])\n",
    "ls_a = pd.DataFrame([])\n",
    "\n",
    "# Get Game Board values for each team to use as index with date\n",
    "sub_root = '//*[@id=\"dnn_ctr490_View_UP\"]/table[3]/tbody/tr[9]/td/table/tbody/tr/td/table/tbody/tr/td[2]/table/tbody/tr/td/table/tbody/tr/td'\n",
    "stats = driver.find_element_by_xpath(sub_root)\n",
    "content_html = stats.get_attribute(\"innerHTML\")\t\n",
    "brd_v = pd.read_html(content_html)[0][0].loc[2]\n",
    "brd_h = pd.read_html(content_html)[0][0].loc[3]\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Y.to_sql(name=table, con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_html(content_html)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_html(content_html,index_col=[0],header=[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = pd.read_html(content_html,index_col=[0],header=[2])[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.Series(X.loc['All Games'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.DataFrame([],index=[[int(dt)],[int(brd_v)]])\n",
    "Y = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for x in X.index:\n",
    "    Y = pd.DataFrame(X.loc[x].apply(lambda x : float64_to_float(x))).transpose()\n",
    "    Y['idx'] = dt+'_'+board\n",
    "    Y.to_sql(name=table+x, con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "z = Y.set_index(keys=list(['game_date'],['board']),drop=True).index\n",
    "z"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y.set_index(keys=['game_date','board'],drop=True).index.levels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y.to_sql?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    ls_a = ls_a.transpose()\n",
    "\n",
    "    ls_a['score_v'] = sc_v\n",
    "    ls_a['team_v'] = tm_v\n",
    "    ls_a['team_h'] = tm_h\n",
    "    ls_a['score_h'] = sc_h  \n",
    "    \n",
    "    all_cols = all_cols.append(ls_a, sort=False).reset_index(drop=True).tail(1)\n",
    "    \n",
    "    all_cols = all_cols.transpose().reset_index(drop=True).transpose()\n",
    "    \n",
    "    all_cols.to_sql(name='statfox_matchups', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_cols.to_sql?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_cols = all_cols.append(ls_a, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X.to_sql(name='statfox_matchups', con=engine, if_exists='update', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = pd.DataFrame({'a':[1,3,6]})\n",
    "Y = pd.DataFrame({'b':[4,2,5]})\n",
    "Y.append(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pk.reset_index(drop=True).transpose()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pk.transpose().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pk.reset_index?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    # Save each row to CSV. Maybe better to use pickles get all possible fields first to make final SQL table\n",
    "    if os.path.isfile(fname) == False:\n",
    "        ls_a.to_csv(fname,index=False)\n",
    "    else:\n",
    "        with open(fname, 'a') as f1:\n",
    "            ls_a.to_csv(f1, index=False, header=False)        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls = pd.read_html(content_html,header=[2])[0]    \n",
    "ls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls['Date'] = pd.to_datetime(ls['Date']) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")\n",
    "ls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls[['score_for','score_against']] = ls['Score'].str.split(\"-\",expand=True)\n",
    "ls[['ovrund_num','ovrund']] = ls['Tot.'].str.split(\" \",expand=True)\n",
    "ls = ls.drop(columns=['Score','Tot.'])      \n",
    "ls = pd.concat([ls], keys=[table])\n",
    "\n",
    "ls = ls.stack()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mdx = ls.index\n",
    "mdx = mdx.set_levels([mdx.levels[0], tdelta, mdx.levels[2]])\n",
    "mdx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s = ls\n",
    "s.reset_index(level=[1],drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.Series(data=ls.values).reset_index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.Series(data=ls.values,index=mdx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mdx.codes[2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mdx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls = pd.Series"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "idx = pd.MultiIndex.from_tuples([(1, u'one'), (1, u'two'),\n",
    "                                    (2, u'one'), (2, u'two')],\n",
    "                                    names=['foo', 'bar'])\n",
    "idx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "arrays = [[1, 1, 2, 2], [6,7], ['red', 'blue', 'red', 'blue']]\n",
    "mdx = pd.MultiIndex.from_product(arrays, names=('number', 'middle', 'color'))\n",
    "mdx = mdx.set_levels([mdx.levels[0],['a','b'],mdx.levels[2]])\n",
    "mdx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.MultiIndex.from_product?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls.index.levels[1] = pd.to_datetime(Xls.index.levels[1]) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls2 = Xls.index.set_levels([pd.to_datetime(Xls.index.levels[1]) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")])\n",
    "Xls2 = Xls.index.swaplevel(i=2,j=1)\n",
    "Xls2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls3 = Xls.reindex(Xls2)\n",
    "Xls3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls2 = Xls.index.swaplevel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[pd.to_datetime(ls.index.levels[1]) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls.index.set_levels([pd.to_datetime(ls.index.levels[1]) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\")])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xls.reindex(pd.to_datetime(ls.index.levels[1]) - pd.to_datetime(gms['date'][x], format=\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls.index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.to_pickle(ls,'pickles/matchups_h.zip')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ls = []\n",
    "ls = pd.read_pickle('pickles/matchups_h.zip')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ar = df.team_v.unique()\n",
    "ar = np.sort(ar,axis=0)\n",
    "df = pd.DataFrame([ar]).transpose()\n",
    "df = df.rename(index=int, columns={0: \"team\"})\n",
    "\n",
    "gl = pd.read_csv('GL2018.CSV', header=0, index_col=0, nrows=test_rows,\n",
    "                     usecols=['date','team_h','team_v','score_h', 'score_v'],\n",
    "                     engine='c',\n",
    "                     parse_dates=['date'],\n",
    "                     infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols = list(range(len(ls_a.transpose())))\n",
    "for n in range(len(ls_a.transpose())):\n",
    "    cols[n] = 'feat_'+str(n)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "soup = BeautifulSoup(element_html, \"html.parser\")\n",
    "for td in tds:\n",
    "    soup_all = soup.find_all('td',{'class': 'matchupCells Text'})\n",
    "    soup_all[td].content\n",
    "    vals = pd.concat([vals,val])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read_html(soup_all)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read_html?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "index.to_flat_index()\n",
    "\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lsall = pd.concat([ls1.melt().dropna(),ls2.melt().dropna(),ls3.melt().dropna(),ls4.melt().dropna()])\n",
    "lsall"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xt = 3\n",
    "if xt in [5,2]:\n",
    "    print('One')\n",
    "elif xt in [3,4]:\n",
    "    print('Two')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = df.loc[3:10,1:10]\n",
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df3 = df2.reindex(index=list(df.loc[3:10,0]),columns=list(df.loc[2,1:10]))\n",
    "df3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2 = pd.DataFrame(df.loc[3:10,1:10],index=list(df.loc[3:10,0]),columns=list(df.loc[2,1:10]))\n",
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "arr = [df.loc[3:10,1:10]]\n",
    "arr?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = lsall.iloc[2:10,0:10]\n",
    "df2 = df.melt(id_vars=[0],value_vars=range(1,10))\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.iloc[2,1:10].to_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Xdf = lsall.reindex(range(len(lsall)))\n",
    "Xdf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = pd.DataFrame(df[1], index=\n",
    "\n",
    "pd.DataFrame?\n",
    "\n",
    "soup = BeautifulSoup(content_html, \"html.parser\")\n",
    "\n",
    "stats = soup.find('table',{'class': 'bg2'}).contents[0]\n",
    "\n",
    "stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
