{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and Model StatFox Matchup Data\n",
    "`mlb_bet_notebooks/model_statfox_matchups.ipynb`\n",
    "- Explore features\n",
    "- Convert historical moneylines to break-even probabilities\n",
    "- Model pre-computed features with RF and maybe PCA\n",
    "- Compare model predictions to historical moneylines\n",
    "    - Use break-even probabilities as alternative model and compare ROC\n",
    "- Try VIF filter\n",
    "- Try k-fold CV\n",
    "- Try grid search model complexity\n",
    "- Try to get player salary\n",
    "    - Combine with addition, subtraction from statfox blobs\n",
    "- Try fix Opening Line feature \n",
    "    - Try openline probability as feature\n",
    "\n",
    "Jonathan Sims 2020-02-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set datetime stamp in YYYYMMDD for all file outputs\n",
    "\n",
    "from datetime import date as dt\n",
    "YMD = dt.today().isoformat().replace('-','') + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import boto3\n",
    "import pandas as pd \n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_fill = pd.read_csv('s3://scrapes-rawhtml-dev/statfox/20200315.statfox_features.tsv.gz', sep='\\t', index_col=0)\n",
    "df_targ = pd.read_csv('s3://scrapes-rawhtml-dev/statfox/20200315.statfox_target.tsv.gz', sep='\\t', index_col=0, header=None, squeeze=True)\n",
    "df_targ_wt = pd.read_csv('s3://scrapes-rawhtml-dev/statfox/20200315.statfox_target_weight.tsv.gz', sep='\\t', index_col=0, header=None, squeeze=True)\n",
    "df_lateline_prob = pd.read_csv('s3://scrapes-rawhtml-dev/statfox/20200315.statfox_lateline_prob.tsv.gz', sep='\\t', index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17573,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17573, 1128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fill.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if df_targ_wt.sum() != 1:\n",
    "    df_targ_wt = df_targ_wt / df_targ_wt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    1.769231\n",
       "1    1.606061\n",
       "2    2.050000\n",
       "3    1.833333\n",
       "4    1.769231\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ_wt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34455.36163974437"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ_wt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matchidx']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make sure matchidx column exists\n",
    "\n",
    "[col for col in df_feat_fill.columns if 'match' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['named: 0.1',\n",
       " 'Bullpen_BB_',\n",
       " 'Bullpen_BSV',\n",
       " 'Bullpen_ERA',\n",
       " 'Bullpen_ER_',\n",
       " 'Bullpen_HR_',\n",
       " 'Bullpen_H_A',\n",
       " 'Bullpen_H_H',\n",
       " 'Bullpen_IP_',\n",
       " 'Bullpen_L_A',\n",
       " 'Bullpen_L_H',\n",
       " 'Bullpen_R_A',\n",
       " 'Bullpen_R_H',\n",
       " 'Bullpen_SO_',\n",
       " 'Bullpen_SV_',\n",
       " 'Bullpen_WHI',\n",
       " 'Bullpen_W_A',\n",
       " 'Bullpen_W_H',\n",
       " 'HitField_Te',\n",
       " 'Overall_Opp',\n",
       " 'Overall_Tea',\n",
       " 'Bullpen_H_R',\n",
       " 'Bullpen_L_R',\n",
       " 'Bullpen_R_R',\n",
       " 'Bullpen_W_R',\n",
       " 'tchidx',\n",
       " 'Bullpen_Pct',\n",
       " '_Opening_Li',\n",
       " 'nth',\n",
       " 'ar',\n",
       " '_Latest_Tot',\n",
       " '_Opening_To']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Partial header names to looks for unknown/erroneous columns\n",
    "\n",
    "f = lambda x: x[2:13]\n",
    "colstrip = pd.Series(df_feat_fill.columns).map(f)\n",
    "[col for col in colstrip.drop_duplicates() if '_h_' not in col and '_v_' not in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make custom score function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_diff = (abs(y - y_pred) + 1 ) * wt - 1\n",
    "y_diff_sum = y_diff.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(y, y_pred, wt):\n",
    "    y_diff = (-1 * abs(y - y_pred) + 1 ) * wt - 1\n",
    "    y_diff_sum = y_diff.sum() / len(y)\n",
    "    return y_diff_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = make_scorer(test_score, wt=pd.Series(df_targ_wt.values))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prof_score = make_scorer(test_score, wt=df_targ_wt)\n",
    "grid = GridSearchCV(RandomForestClassifier(n_jobs=-1), param_grid={'n_estimators':[200]}, scoring=prof_score)\n",
    "grid.fit(df_feat_fill[:14000], df_targ[:14000])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid.score(df_feat_fill[14000:], df_targ[14000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate close moneyline ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targ_dropna = df_targ[df_lateline_prob.isna() == False]\n",
    "df_lateline_prob_dropna = df_lateline_prob[df_lateline_prob.isna() == False]\n",
    "df_targ_wt_dropna = df_targ_wt[df_lateline_prob.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5071739747513021"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df_targ_dropna, df_lateline_prob_dropna, sample_weight=df_targ_wt_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17573,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17573, 1128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17573,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ_wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76923077, 1.60606061, 2.05      , ..., 1.625     , 2.15      ,\n",
       "       1.60606061])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targ_wt.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for cnt in range(0,10):\n",
    "\n",
    "    df_feat_fill_train, df_feat_fill_test, df_targ_train, df_targ_test, df_targ_wt_train, df_targ_wt_test = train_test_split(df_feat_fill, df_targ, df_targ_wt, test_size=0.2, random_state=cnt)\n",
    "\n",
    "#     clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=cnt, \n",
    "#                                  max_depth=4, \n",
    "#                                  min_samples_split=8)\n",
    "    complexity_par = {'class_weight': 'balanced', \n",
    "                      'criterion': 'entropy', \n",
    "                      'max_depth': 2, \n",
    "                      'min_samples_split': 9, \n",
    "                      'oob_score': False}\n",
    "    \n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, **complexity_par)\n",
    "    \n",
    "    df_fit = clf.fit(df_feat_fill_train, df_targ_train, df_targ_wt_train)\n",
    "#     df_fit = clf.fit(df_feat_fill_train, df_targ_train)\n",
    "    df_pred = df_fit.predict(df_feat_fill_test)\n",
    "    \n",
    "#     print(roc_auc_score(df_targ_test, df_pred, sample_weight=df_targ_wt_test))\n",
    "#     print(roc_auc_score(df_targ_test, df_pred))\n",
    "    print(test_score(df_targ_test, df_pred, df_targ_wt_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF with AUC and no PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17573, 1128)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fill.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nsplit = round(len(df_feat_fill)*0.8)\n",
    "nsplit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[col for col in df_feat_fill.columns if '_NaN' in col]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_feat_fill_train = df_feat_fill.iloc[:nsplit]\n",
    "df_targ_train = df_targ.iloc[:nsplit]\n",
    "df_feat_fill_test = df_feat_fill.iloc[nsplit:]\n",
    "df_targ_test = df_targ.iloc[nsplit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big gridsearch with n_jobs=1 and no sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "### Define len for subset for development\n",
    "\n",
    "_dev_len = 16000\n",
    "\n",
    "\n",
    "### Define feature and target data\n",
    "\n",
    "# X = df_feat_fill[:_dev_len].to_numpy()\n",
    "# y = df_targ[:_dev_len].to_numpy()\n",
    "X = df_feat_fill[:_dev_len]\n",
    "y = df_targ[:_dev_len]\n",
    "\n",
    "\n",
    "### Define custom profit score function\n",
    "\n",
    "prof_score = make_scorer(test_score, wt=df_targ_wt)\n",
    "\n",
    "\n",
    "### Save number of splits for leave-one-out CV\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "splits = loo.split(X)\n",
    "\n",
    "\n",
    "### Grid of hyperparams to search\n",
    "\n",
    "max_depth_par = range(2,3)\n",
    "# min_samples_split_par = range(24,32)\n",
    "min_samples_leaf_par = range(6,7)\n",
    "criterion_par = ['entropy']\n",
    "class_weight_par = ['balanced_subsample']\n",
    "oob_score_par = [False]\n",
    "\n",
    "parameters = {'max_depth':max_depth_par, \n",
    "#               'min_samples_split':min_samples_split_par, \n",
    "              'min_samples_leaf':min_samples_leaf_par, \n",
    "              'criterion':criterion_par, \n",
    "              'class_weight':class_weight_par, \n",
    "              'oob_score':oob_score_par}\n",
    "#                 }\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=1)\n",
    "clf = GridSearchCV(rfc, parameters, n_jobs=-1, scoring=prof_score, cv=splits)\n",
    "\n",
    "fit = clf.fit(X, y)\n",
    "\n",
    "par = clf.best_params_\n",
    "# fea = clf.feature\n",
    "scr = clf.score(X, y)\n",
    "sco = clf.score(df_feat_fill[_dev_len:], df_targ[_dev_len:])\n",
    "\n",
    "pkl = [fit, par, scr, sco]\n",
    "# with open(YMD+'GridSearchCV.RandomForest.pkl', 'wb') as wb:\n",
    "#     pickle.dump(pkl, wb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('20200319.GridSearchCV.RandomForest.pkl', 'rb') as rb:\n",
    "    test = pickle.load(rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in pkl:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4a2bd8eab386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feat_fill\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_dev_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_targ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_dev_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.score(df_feat_fill[_dev_len:], df_targ[_dev_len:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big gridsearch with n_jobs=2 and sample weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score() got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: score() got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "### Define len for subset for development\n",
    "\n",
    "_dev_len = 16000\n",
    "\n",
    "\n",
    "### Define feature and target data\n",
    "\n",
    "# X = df_feat_fill[:_dev_len].to_numpy()\n",
    "# y = df_targ[:_dev_len].to_numpy()\n",
    "X = df_feat_fill[:_dev_len]\n",
    "y = df_targ[:_dev_len]\n",
    "\n",
    "\n",
    "### Define custom profit score function\n",
    "\n",
    "prof_score = make_scorer(test_score, wt=df_targ_wt)\n",
    "\n",
    "\n",
    "### Save number of splits for leave-one-out CV\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "splits = loo.split(X)\n",
    "\n",
    "\n",
    "### Grid of hyperparams to search\n",
    "max_depth_par = range(1,5)\n",
    "# min_samples_split_par = range(15,30)\n",
    "# min_samples_leaf_par = range(3,15)\n",
    "# criterion_par = ['gini', 'entropy']\n",
    "# class_weight_par = ['balanced', 'balanced_subsample']\n",
    "oob_score_par = [False, True]\n",
    "\n",
    "parameters = {'max_depth':max_depth_par, \n",
    "#               'min_samples_split':min_samples_split_par, \n",
    "#               'min_samples_leaf':min_samples_leaf_par, \n",
    "#               'criterion':criterion_par, \n",
    "#               'class_weight':class_weight_par, \n",
    "              'oob_score':oob_score_par}\n",
    "#                 }\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "clf = GridSearchCV(rfc, parameters, n_jobs=-1, scoring=prof_score, cv=10)\n",
    "\n",
    "\n",
    "### Write estimator and results to pickles\n",
    "\n",
    "fit = clf.fit(X, y, sample_weight=df_targ_wt[:_dev_len])\n",
    "par = clf.best_params_\n",
    "scr = clf.score(X, y)\n",
    "sco = clf.score(df_feat_fill[_dev_len:], df_targ[_dev_len:])\n",
    "scw = clf.score(df_feat_fill[_dev_len:], df_targ[_dev_len:], sample_weight=df_targ_wt[_dev_len:])\n",
    "\n",
    "pkl = [fit, par, scr, sco, scw]\n",
    "with open(YMD+'GridSearchCV.RandomForest.Weight.pkl', 'wb') as wb:\n",
    "    pickle.dump(pkl, wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(df_feat_fill[_dev_len:], df_targ[_dev_len:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `20200318`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.546827326160997"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = df_feat_fill[_dev_len:].to_numpy()\n",
    "y_val = df_targ[_dev_len:].to_numpy()\n",
    "\n",
    "clf_pred = clf.predict(X_val)\n",
    "roc_auc_score(y_val, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_fill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt in range(1,100,10):\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(df_feat_fill, df_targ, test_size=0.2, random_state=cnt)\n",
    "\n",
    "    ### Standarize data\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    np_scaled = min_max_scaler.fit_transform(df_feat_fill)\n",
    "    df_feat_fill_st = pd.DataFrame(np_scaled)\n",
    "\n",
    "    df_feat_fill_train, df_feat_fill_test, df_targ_train, df_targ_test = train_test_split(df_feat_fill_st, df_targ, test_size=0.2)\n",
    "\n",
    "    clf = AdaBoostClassifier()\n",
    "    df_fit = clf.fit(df_feat_fill_train, df_targ_train)\n",
    "    df_pred = df_fit.predict(df_feat_fill_test)\n",
    "    \n",
    "    print(roc_auc_score(df_targ_test, df_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunPCA(X,n):\n",
    "    \"\"\"Takes an input data set X and returns n principal components\n",
    "    \"\"\"\n",
    "    # Create a scaler object\n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler to the features and transform\n",
    "    X_std = sc.fit_transform(X)\n",
    "\n",
    "    # Create a pca object with the 2 components as a parameter\n",
    "    pca = decomposition.PCA(n_components=n)\n",
    "\n",
    "    # Fit the PCA and transform the data\n",
    "    X_std_pca = pca.fit_transform(X_std)\n",
    "    \n",
    "    return X_std_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_fill_train = df_feat_fill.iloc[:nsplit]\n",
    "df_targ_train = df_targ.iloc[:nsplit]\n",
    "df_feat_fill_test = df_feat_fill.iloc[nsplit:]\n",
    "df_targ_test = df_targ.iloc[nsplit:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create standardized, principal components\n",
    "std_pca_train = RunPCA(df_feat_fill_train,50)\n",
    "std_pca_df = RunPCA(df_feat_fill_test,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice with PCA\n",
    "\n",
    "transform df with fit on train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune n_components param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   0.5406012163200662\n",
      "6   0.5254810861839616\n",
      "11   0.5257931631733549\n",
      "16   0.5242600849629604\n",
      "21   0.5194033868155274\n",
      "26   0.5261052401627482\n",
      "31   0.5394582343464133\n",
      "36   0.5252879885467745\n",
      "41   0.5288456662258579\n",
      "46   0.530548436299235\n",
      "51   0.512311437231565\n",
      "56   0.5231171029893075\n",
      "61   0.5362496927992135\n",
      "66   0.5289373388414922\n",
      "71   0.5312876686678604\n",
      "76   0.5225846216261553\n",
      "81   0.5338584028679876\n",
      "86   0.5248198730626845\n",
      "91   0.5148587656574877\n",
      "96   0.531898169278361\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "\n",
    "for cnt in range(1,100,5):\n",
    "\n",
    "    ### Create a pca object with the 2 components as a parameter\n",
    "    \n",
    "    pca = decomposition.PCA(n_components=50)\n",
    "\n",
    "    df_feat_fill_train, df_feat_fill_test, df_targ_train, df_targ_test = train_test_split(df_feat_fill, df_targ, test_size=0.1, random_state=1)\n",
    "\n",
    "    X1 = df_feat_fill_train\n",
    "    X2 = df_feat_fill_test\n",
    "\n",
    "    ### Create a scaler object\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "\n",
    "    ### Fit the scaler to the features and transform\n",
    "    \n",
    "    X1_std = sc.fit_transform(X1)\n",
    "    X2_std = sc.fit(X1).transform(X2)\n",
    "\n",
    "    ### Fit the PCA and transform the data\n",
    "    \n",
    "    X1_std_pca = pca.fit_transform(X1_std)\n",
    "    X2_std_pca = pca.fit(X1_std).transform(X2_std)\n",
    "\n",
    "    std_pca_train = X1_std_pca\n",
    "    std_pca_df = X2_std_pca\n",
    "\n",
    "    clf = AdaBoostClassifier(n_estimators=100, random_state=1)\n",
    "    df_fit = clf.fit(std_pca_train, df_targ_train)\n",
    "    df_pred = df_fit.predict(std_pca_df)\n",
    "    score = roc_auc_score(df_targ_test, df_pred)\n",
    "    \n",
    "    ### Append score to dict\n",
    "    \n",
    "    scores[cnt] = score\n",
    "    \n",
    "    ### Print for OCD\n",
    "    print(cnt,' ',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([clf.feature_importances_, df_feat_fill_train.columns]).transpose().sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([clf.feature_importances_, df_feat_fill_train.columns]).transpose.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_fill_desc = df_feat_fill_train.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_fill_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_feat_fill_desc.columns:\n",
    "    print(df_feat_fill_desc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "for cnt in range(4):\n",
    "    scores[cnt] = cnt*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
